{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU or CPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\\n  zip_ref.extractall(\"data_faces/\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n",
    "  zip_ref.extractall(\"data_faces/\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root = '/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba'\n",
    "img_list = os.listdir(root)\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"/home/luser/autoencoder_attacks/train_aautoencoders/list_attr_celeba.csv\")\n",
    "#df = df[['image_id', 'Smiling']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#get all the row titles\n",
    "df.index\n",
    "# get all the column titles\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!rm -rf data\\n!mkdir data && mkdir data/smile && mkdir data/no_smile'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make directories\n",
    "\n",
    "'''!rm -rf data\n",
    "!mkdir data && mkdir data/smile && mkdir data/no_smile'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s0 = 0\n",
    "s1 = 0\n",
    "s2 = 0\n",
    "s3 = 0\n",
    "s4 = 0\n",
    "s5 = 0\n",
    "s6 = 0\n",
    "s7 = 0\n",
    "\n",
    "num = 700000\n",
    "\n",
    "for i, (_, i_row) in enumerate(df.iterrows()):\n",
    "  '''if s0 < num: # for bald\n",
    "    if i_row['Bald'] == 1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == 1 and i_row['Eyeglasses'] == -1:\n",
    "      s0 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAbald/bald_disjoined/' + i_row['image_id'])\n",
    "  \n",
    "  if s1 < num: # for hat\n",
    "    #if i_row['Wearing_Hat'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == 1 and i_row['No_Beard'] == 1 and i_row['Male'] == 1 and i_row['Eyeglasses'] == -1:\n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_hat/Wearing_Hat_disjoined/' + i_row['image_id'])\n",
    "  \n",
    "  if s1 < num: # for beard\n",
    "    #if i_row['No_Beard'] == -1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == -1 and i_row['Male'] == 1 and i_row['Eyeglasses'] == -1:\n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAbeard/withBeard_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Eyeglasses'] == 1 and i_row['Gray_Hair'] == 1  and i_row['Young'] == -1:\n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebAblackWomenGlasses_d/black_women_eyeglass_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Eyeglasses'] == 1 and i_row['Gray_Hair'] == 1  and i_row['Young'] == -1:\n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebAoldWomenGlasses_d/old_women_eyeglass_disjoined/' + i_row['image_id'])'''\n",
    "\n",
    "  '''if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Black_Hair'] == 1  and i_row['Pale_Skin'] == -1 and i_row['Big_Lips'] == 1 and i_row['Big_Nose'] == 1 and i_row['Wearing_Lipstick'] == 1 and i_row['Wearing_Earrings'] == 1:     \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_blackWomen_d/blackWomen_disjoined/' + i_row['image_id'])'''\n",
    "\n",
    "\n",
    "  '''if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Pale_Skin'] == 1 and i_row['Eyeglasses'] == -1 and i_row['Blond_Hair'] == 1 :      \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_whiteWomen/whiteWomen_d/' + i_row['image_id'])'''\n",
    "\n",
    "\n",
    "  '''if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Pale_Skin'] == 1 and i_row['Eyeglasses'] == -1 :      \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_generalWhiteWomen_d/generalWhiteWomen_disjoined/' + i_row['image_id'])'''\n",
    "\n",
    "\n",
    "  '''if s1 < num: # black men\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Male'] == 1 and i_row['Black_Hair'] == 1  and i_row['Pale_Skin'] == -1 and i_row['Big_Lips'] == 1 and i_row['Big_Nose'] == 1 :     \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_blackMen_d/blackMen_disjoined/' + i_row['image_id'])'''\n",
    "\n",
    "  '''if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Male'] == 1 and i_row['Pale_Skin'] == 1 :      \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_generalWhiteMen_d/generalWhiteMen_disjoined/' + i_row['image_id'])'''\n",
    "\n",
    "  '''if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Young'] == 1 and i_row['Male'] == 1 :      \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_youngMen_d/youngMen_disjoined' + i_row['image_id'])\n",
    "\n",
    "  if s2 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Young'] == 1 and i_row['Male'] == -1 :      \n",
    "      s2 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_youngWomen_d/youngWomen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s3 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Young'] == -1 and i_row['Male'] == 1 and i_row['Gray_Hair'] == 1 :      \n",
    "      s3 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_oldMen_d/oldMen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s4 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Young'] == -1 and i_row['Male'] == -1 and i_row['Gray_Hair'] == 1:      \n",
    "      s4 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_oldWomen_d/oldWomen_disjoined/' + i_row['image_id'])'''\n",
    "\n",
    "\n",
    "  if s0 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Black_Hair'] == 1  and i_row['Pale_Skin'] == -1 and i_row['Big_Lips'] == 1 and i_row['Big_Nose'] == 1 and i_row['Wearing_Lipstick'] == 1 and i_row['Wearing_Earrings'] == 1 and i_row['Wearing_Earrings'] == 1 and i_row['Young'] == 1 and i_row['Gray_Hair'] == -1 :     \n",
    "      s0 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_youngblackWomen_d/youngblackWomen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s1 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Black_Hair'] == 1  and i_row['Pale_Skin'] == -1 and i_row['Big_Lips'] == 1 and i_row['Big_Nose'] == 1 and i_row['Wearing_Lipstick'] == 1 and i_row['Wearing_Earrings'] == 1 and i_row['Wearing_Earrings'] == 1 and i_row['Young'] == -1 :     \n",
    "      s1 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_oldblackWomen_d/oldblackWomen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s2 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Pale_Skin'] == 1 and i_row['Eyeglasses'] == -1 and i_row['Young'] == 1 and i_row['Gray_Hair'] == -1 :      \n",
    "      s2 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_younggeneralWhiteWomen_d/younggeneralWhiteWomen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "\n",
    "  if s3 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Bald'] == -1 and i_row['Wearing_Hat'] == -1 and i_row['No_Beard'] == 1 and i_row['Male'] == -1 and i_row['Pale_Skin'] == 1 and i_row['Eyeglasses'] == -1 and i_row['Young'] == -1 and i_row['Gray_Hair'] == 1 :      \n",
    "      s3 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_oldgeneralWhiteWomen_d/oldgeneralWhiteWomen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "  if s4 < num: # black men\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Male'] == 1 and i_row['Black_Hair'] == 1  and i_row['Pale_Skin'] == -1 and i_row['Big_Lips'] == 1 and i_row['Big_Nose'] == 1 and i_row['Young'] == 1 and i_row['Gray_Hair'] == -1 :     \n",
    "      s4 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_youngblackMen_d/youngblackMen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "\n",
    "  if s5 < num: # black men\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Male'] == 1 and i_row['Black_Hair'] == 1  and i_row['Pale_Skin'] == -1 and i_row['Big_Lips'] == 1 and i_row['Big_Nose'] == 1 and i_row['Young'] == -1 :     \n",
    "      s5 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_oldblackMen_d/oldblackMen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "\n",
    "  if s6 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Male'] == 1 and i_row['Pale_Skin'] == 1 and i_row['Young'] == 1 and i_row['Gray_Hair'] == -1 :      \n",
    "      s6 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_younggeneralWhiteMen_d/younggeneralWhiteMen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "\n",
    "  if s7 < num: # for female eye glasses\n",
    "    #if i_row['Male'] == -1 and i_row['Eyeglasses'] == 1:\n",
    "    if i_row['Male'] == 1 and i_row['Pale_Skin'] == 1 and i_row['Young'] == -1 and i_row['Gray_Hair'] == 1 :      \n",
    "      s7 += 1\n",
    "      shutil.copyfile('/home/luser/autoencoder_attacks/train_aautoencoders/data_faces/img_align_celeba/' + i_row['image_id'], '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized//celebA_oldgeneralWhiteMen_d/oldgeneralWhiteMen_disjoined/' + i_row['image_id'])\n",
    "\n",
    "\n",
    "  if s0 == num and s1 == num and s2 == num and s3 == num and s4 == num  and s5 == num  and s6 == num  and s7 == num:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  84434\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_men_d/men_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_men_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  118165\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_women_d/women_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_women_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  156734\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_young_d/young_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_young_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  45865\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_old_d/old_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_old_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  53448\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_youngMen_d/youngMen_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_youngMen_d'\n",
    "femaleGlass_list = os.listdir(female_glass_parent)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  7003\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_oldMen_d/oldMen_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_oldMen_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  1116\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_oldWomen_d/oldWomen_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_oldWomen_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female glass List:  103287\n"
     ]
    }
   ],
   "source": [
    "#femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebAWomenGlasses/women_eyeglass'\n",
    "femaleGlass_address = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_youngWomen_d/youngWomen_disjoined'\n",
    "female_glass_parent = '/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/celebA_youngWomen_d'\n",
    "femaleGlass_list = os.listdir(femaleGlass_address)\n",
    "#femaleGlass_list.extend(os.listdir('/home/luser/autoencoder_attacks/train_aautoencoders/celebA_categorized/women_eyeglass/'))\n",
    "print(\"female glass List: \", len(femaleGlass_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "          transforms.Resize((64, 64)),\n",
    "          transforms.ToTensor()\n",
    "          ])\n",
    "\n",
    "batch_size = 84434\n",
    "celeba_data = datasets.ImageFolder(female_glass_parent, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#celeba_data = celeba_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['men_disjoined']\n",
      "84434\n"
     ]
    }
   ],
   "source": [
    "print(celeba_data.classes)\n",
    "print(len(celeba_data))\n",
    "\n",
    "considered_list = femaleGlass_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set, test_set = torch.utils.data.random_split(celeba_data, [int(len(considered_list) * 0.75), len(considered_list) - int(len(considered_list) * 0.75)])\n",
    "train_data_size = len(train_set)\n",
    "test_data_size = len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(train_set,batch_size=batch_size, shuffle=True)\n",
    "testLoader  = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63325\n",
      "21109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(train_data_size)\n",
    "print(test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image, label) in enumerate(trainLoader):\n",
    "    images, label = image.to(device), label.to(device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63325, 3, 64, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "#from nvae.utils import add_sn\n",
    "#from nvae.vae_celeba import NVAE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from nvae.utils import reparameterize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE_big(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (13): ReLU()\n",
       "    (14): Flatten()\n",
       "  )\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): UnFlatten()\n",
       "    (1): ConvTranspose2d(1024, 256, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (2): ReLU()\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(128, 64, kernel_size=(6, 6), stride=(2, 2))\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU()\n",
       "    (13): ConvTranspose2d(64, 3, kernel_size=(6, 6), stride=(2, 2))\n",
       "    (14): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use GPU or CPU for training\n",
    "\n",
    "from vae import VAE_big\n",
    "\n",
    "model = VAE_big(device, image_channels=3).to(device)\n",
    "\n",
    "train_data_size = 162079\n",
    "epochs = 199\n",
    "\n",
    "model.load_state_dict(torch.load('/home/luser/autoencoder_attacks/saved_celebA/checkpoints/celebA_CNN_VAE_big_trainSize'+str(train_data_size)+'_epochs'+str(epochs)+'.torch'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    ae_perturbed_embeds = model.encoder(images) # some confusion here. Why are you doin whatever you doing . Should not the input be  data + noise_outputs ?\n",
    "    mu1, logvar1 = model.fc1(ae_perturbed_embeds), model.fc2(ae_perturbed_embeds)\n",
    "    std1 = logvar1.mul(0.5).exp_()\n",
    "    esp1 = torch.randn(*mu1.size()).to(device)\n",
    "    z1 = mu1 + std1 * esp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([63325, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
